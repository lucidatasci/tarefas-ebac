{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f7619a-a159-47cd-a355-ba51f3952a5b",
   "metadata": {},
   "source": [
    "# Exercicio 2 - Modulo 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01497316-620c-404b-a39a-20581cc8600f",
   "metadata": {},
   "source": [
    "#### 1) Monte um passo a passo para o algoritmo RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d63e2e-010a-492e-9881-d34305d74af0",
   "metadata": {},
   "source": [
    "1 - A partir de um dataset, realizar a amostragem com reposição (ou Bootstrap), de forma a montar um número desejado de conjuntos reamostrados. \n",
    "Reamostrar as colunas em novo número em relação ao número original, de acordo com o tipo de árvore a ser utilizado. 1/3 para Regressão, raiz quadrada para Classificação. \n",
    "\n",
    "2 - Ajustar um modelo de árvore de decisão em cada conjunto diferente criado. Podem ser árvores de classificação ou de regressão. \n",
    "\n",
    "3 - Com as predições de cada modelo, agregar para determinar o resultado final. Ex: Média para árvore de regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293014f-351f-440d-820e-54b9507a02b6",
   "metadata": {},
   "source": [
    "#### 2) Explique com suas palavras o Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053635e5-ffff-449f-87b1-2b333f704567",
   "metadata": {},
   "source": [
    "É um método criado por Leo Breiman a fim de reduzir ainda mais a variância do Bagging, e evitar o overfitting nos modelos de árvore de decisão. A partir de um conjunto de dados, os dados são reamostrados (com reposição) em vários conjuntos, e as variáveis também são reamostradas em números menores, criando conjuntos de dados que podem ser completamente diferentes. Uma árvore de decisão é modelada a partir de cada novo conjunto individual, e o resultado final é agregado utilizando todos os modelos gerados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3586c-28ab-482b-94ad-8bfb99351007",
   "metadata": {},
   "source": [
    "#### 3) Qual a diferença entre Bagging e Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5d186-bb47-4902-902c-a6b18c9c3818",
   "metadata": {},
   "source": [
    "O Random Forest é uma variação mais complexa do Bagging, onde além de reamostragem das linhas, as colunas também são reamostradas, criando mais diversidade entre os conjuntos de dados gerados. No Bagging todas as colunas são mantidas como no original, enquanto no Random Forest uma porção menor das colunas são selecionadas em cada reamostragem. No Random Forest os modelos ajustados são sempre árvores de decisão, enquanto no Bagging outros modelos podem ser usados. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75663496-39f9-4869-90f3-6b21ea200380",
   "metadata": {},
   "source": [
    "#### 4) Implementar em python o Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e711d1d-01a8-4cdd-89af-588b16706be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "df = pd.read_csv(\"credit_scoring.csv\")\n",
    "df2 = df.drop(['mau','data_ref','id_cliente','sexo','tipo_renda','educacao','estado_civil','tipo_residencia'], axis=1)\n",
    "#Removi todas variáveis categóricas pra simplificar\n",
    "\n",
    "y = df2['renda']\n",
    "X = df2.drop('renda', axis=1)\n",
    "\n",
    "# Parâmetros do Random Forest\n",
    "n_trees = 10  # Número de árvores\n",
    "max_depth = 3  # Profundidade máxima das árvores\n",
    "bootstrap_size = len(X)  # Tamanho do conjunto de bootstrap (amostragem com reposição)\n",
    "\n",
    "\n",
    "# Construindo o Random Forest\n",
    "forest = []\n",
    "for n in range(n_trees):\n",
    "    # Amostragem com reposição para criar o conjunto de bootstrap\n",
    "    bootstrap_indices = np.random.choice(bootstrap_size, bootstrap_size, replace=True)\n",
    "    X_bootstrap = X.iloc[bootstrap_indices]\n",
    "    y_bootstrap = y.iloc[bootstrap_indices]\n",
    "\n",
    "    # Construir árvore de decisão\n",
    "    tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    tree.fit(X_bootstrap, y_bootstrap)\n",
    "\n",
    "    # Adicionar árvore ao Random Forest\n",
    "    forest.append(tree)\n",
    "\n",
    "# Fazendo as previsões com o Random Forest\n",
    "predictions = []\n",
    "for tree in forest:\n",
    "    predictions.append(tree.predict(X))\n",
    "\n",
    "\n",
    "#Calculando a média das previsões\n",
    "mean_predictions = np.mean(predictions)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da95375-2a24-4766-9fef-2fee02292851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
